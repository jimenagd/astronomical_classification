{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Fold Cross Validation\n",
    "A different type of cross validation, other than the 70-30 split we did, is called K-folding.\n",
    "\n",
    "With K-folding, we take a different piece of the training set as the test set with each fold. In turn, every data point can be used to evaluate once. This is good for preventing overfitting and underfitting. \n",
    "\n",
    "![alt text](https://miro.medium.com/max/676/1*OoDfxcxpccB6tvZ2Hw0XzQ.png \"K_fold\")\n",
    "\n",
    "\n",
    "With each round of model fitting, we store the prediction accuracy in a list. After all scores are extracted from every fold, we calculate the mean of all the scores. \n",
    "\n",
    "\n",
    "In this notebook, we'll try out K-folding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = pd.read_csv('data/Y.csv')\n",
    "X_feat = pd.read_csv('data/X_feat.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "#Prepare cross validation with 5 folds\n",
    "kfold = KFold(5, True)\n",
    "logreg = LogisticRegression(solver='lbfgs')\n",
    "\n",
    "#List of accuracy scores\n",
    "accs = []\n",
    "\n",
    "#Enumerate splits\n",
    "for train_index, test_index in kfold.split(X_feat):\n",
    "    Xc_train, Xc_test = X_feat.iloc[train_index], X_feat.iloc[test_index]\n",
    "    yc_train, yc_test = Y.iloc[train_index], Y.iloc[test_index]\n",
    "    #Train model\n",
    "    logreg.fit(Xc_train, yc_train)\n",
    "    #Evaluate on test set\n",
    "    y_pred = logreg.predict(Xc_test)\n",
    "    #store accuracy into list\n",
    "    accs.append(logreg.score(Xc_test, yc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7076433121019108,\n",
       " 0.6942675159235668,\n",
       " 0.710828025477707,\n",
       " 0.6927979604843849,\n",
       " 0.7017208413001912]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Results of accuracy scores\n",
    "accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7014515310575521"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Take the mean \n",
    "import statistics as st\n",
    "st.mean(accs)\n",
    "#Mean of all scores = ~70%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
